{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "I170216_NLP5",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoZKwXUnwhfs"
      },
      "source": [
        "                                                Muhammad Mohsin \n",
        "\n",
        "                                                     i170216\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "                                          --------------REPORT-------------\n",
        "\n",
        "**Using Only NaiveBayes**: \n",
        "\n",
        "      Accuracy:  0.6946564885496184\n",
        "      Precision:  0.743421052631579\n",
        "      Recall:  0.7243589743589743\n",
        "      f1 score:  0.7337662337662338\n",
        "\n",
        "**Using NaiveBayes (StopWords Removed)**\n",
        "\n",
        "      Accuracy:  0.7022900763358778\n",
        "      Precision:  0.7302631578947368\n",
        "      Recall:  0.74\n",
        "      f1 score:  0.7350993377483444\n",
        "\n",
        "**Using Boolean NaiveBayes**\n",
        "\n",
        "      Accuracy:  0.7824427480916031\n",
        "      Precision:  0.868421052631579\n",
        "      Recall:  0.7719298245614035\n",
        "      f1 score:  0.8173374613003096\n",
        "\n",
        "\n",
        "**Using Boolean NaiveBayes (StopWords Removed)**\n",
        "\n",
        "      Accuracy:  0.7633587786259542\n",
        "      Precision:  0.8552631578947368\n",
        "      Recall:  0.7558139534883721\n",
        "      f1 score:  0.8024691358024691\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                               CONCLUSION: \n",
        "  \n",
        "      As from the figures above we can see Boolean Naive Bayes has a better accuracy though removing stop words \n",
        "      from the boolean Naive Bayes algorithm showed a decrese in accuracy\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxyVAaQl_5vk"
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict \n",
        "import os\n",
        "import math"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Tcu1lJ_9aq"
      },
      "source": [
        "def getFilenames():\n",
        "  train_real_filename = os.listdir('/content/drive/MyDrive/data/Train/Real')\n",
        "  train_fake_filename = os.listdir('/content/drive/MyDrive/data/Train/Fake')\n",
        "  return train_real_filename, train_fake_filename"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKh2fQ-oAKpH"
      },
      "source": [
        "#====================================================OPENING TRAINING FILES============================================================ \n",
        "def CreateDataset(train_real_filename, train_fake_filename):\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^۔&*_~'''\n",
        "  train_real = [] \n",
        "  train_fake = [] \n",
        "  for filename in train_real_filename: \n",
        "    path =  \"/content/drive/MyDrive/data/Train/Real/\" + filename\n",
        "    file = open(path)\n",
        "    news = file.read()\n",
        "    news = news.strip()\n",
        "    no_punct = \"\"\n",
        "    for char in news:\n",
        "      if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        " \n",
        "    train_real.append(no_punct)\n",
        "    file.close()\n",
        "\n",
        "  for filename in train_fake_filename: \n",
        "    path =  \"/content/drive/MyDrive/data/Train/Fake/\" + filename\n",
        "    file = open(path)\n",
        "    news = file.read()\n",
        "    news = news.strip()\n",
        "    no_punct = \"\"\n",
        "    for char in news:\n",
        "      if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        " \n",
        "    train_fake.append(no_punct)\n",
        "    file.close()\n",
        "  \n",
        " \n",
        "   \n",
        "  \n",
        "  return train_real, train_fake \n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-swdN0dWF-K6"
      },
      "source": [
        "#====================================================CREATING VOCABULARY============================================================\n",
        "def createVocabulary(train_real, train_fake):\n",
        "  vocab = defaultdict(int)\n",
        "  for news in train_real: \n",
        "    token = news.split()\n",
        "    for word in token:  \n",
        "      vocab[word] += 1\n",
        "  for news in train_fake: \n",
        "    token = news.split()\n",
        "    for word in token:  \n",
        "      vocab[word] += 1\n",
        "  \n",
        "  vocab_words = []\n",
        "  for word,_ in vocab.items():\n",
        "    vocab_words.append(word)\n",
        "\n",
        "  return vocab_words \n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMo_kYH1ElP2"
      },
      "source": [
        "#====================================================CALCULATING CLASS PROBABILTIES============================================================\n",
        "def getClassProb(count_real, count_fake): \n",
        "  prob_real = count_real / (count_real + count_fake)\n",
        "  prob_fake = count_fake / (count_real + count_fake) \n",
        "  return prob_real, prob_fake\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNQFJPJFJ8uS"
      },
      "source": [
        "#====================================================CREATING DOC FOR A GIVEN CLASS============================================================\n",
        "def createDoc(data):\n",
        "  doc = [] \n",
        "  for datapoint in data: \n",
        "    datapoint = datapoint.split() \n",
        "    for word in datapoint: \n",
        "      doc.append(word) \n",
        "\n",
        "  doc_dict = defaultdict(int)\n",
        "  for word in doc:\n",
        "    doc_dict[word] += 1 # increment element's value by 1\n",
        "  \n",
        "  return doc, doc_dict\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKppevCyNdN1"
      },
      "source": [
        "#====================================================NAIVE BAYES TRAINING============================================================\n",
        "def NaiveBayes(train_real, train_fake):   \n",
        "  training = [train_real, train_fake]\n",
        "  probability = []\n",
        "  vocab = createVocabulary(train_real, train_fake)  \n",
        "  prob_real, prob_fake = getClassProb(len(train_real), len(train_fake))\n",
        "  # 0: REAL \n",
        "  # 1: FAKE\n",
        "  for i in range(0,2): #for 2 classes only \n",
        "    prob = []   \n",
        "    doc, doc_dict = createDoc(training[i])   \n",
        "    count_words = [] \n",
        "    for word in vocab: \n",
        "      n = doc.count(word)\n",
        "      numerator = n + 1\n",
        "      denominator = len(doc) + len(vocab)\n",
        "      Prob_word_given_class = numerator/ denominator\n",
        "      prob.append(Prob_word_given_class) \n",
        "    probability.append(prob)  \n",
        "  return probability"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxtBo9T2zpL"
      },
      "source": [
        "**TESTING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxL7XC-IRd2q"
      },
      "source": [
        "#====================================================OPENING TESTING FILES============================================================ \n",
        "def getTestFilenames():\n",
        "  test_real_filename = os.listdir('/content/drive/MyDrive/data/Test/Real')\n",
        "  test_fake_filename = os.listdir('/content/drive/MyDrive/data/Test/Fake')\n",
        "  return test_real_filename, test_fake_filename\n",
        "  \n",
        "def CreateTestDataset(test_real_filename, test_fake_filename):\n",
        "  test_real = [] \n",
        "  test_fake = []\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^۔&*_~''' \n",
        "  for filename in test_real_filename: \n",
        "    path =  \"/content/drive/MyDrive/data/Test/Real/\" + filename\n",
        "    file = open(path)\n",
        "    news = file.read()\n",
        "    news = news.strip() \n",
        "    no_punct = \"\"\n",
        "    for char in news:\n",
        "      if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        " \n",
        "    test_real.append(no_punct)\n",
        "    file.close()\n",
        "\n",
        "  for filename in test_fake_filename: \n",
        "    path =  \"/content/drive/MyDrive/data/Test/Fake/\" + filename\n",
        "    file = open(path)\n",
        "    news = file.read()\n",
        "    news = news.strip()\n",
        "    no_punct = \"\"\n",
        "    for char in news:\n",
        "      if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        " \n",
        "    test_fake.append(no_punct)\n",
        "    file.close()\n",
        "  \n",
        "  return test_real, test_fake \n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgbRBrfTq40O"
      },
      "source": [
        "**REMOVING STOP WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoPBmeszqQxc"
      },
      "source": [
        "def readStopWords(): \n",
        "  stop_word = []\n",
        "  file = open(\"/content/drive/MyDrive/data/stopwords-ur.txt\", 'r')\n",
        "  Lines = file.readlines()\n",
        "  for line in Lines: \n",
        "    line = line.strip()  \n",
        "    stop_word.append(line)   \n",
        "  return stop_word\n",
        "stop_words = readStopWords()\n",
        "\n",
        "def removeStopWords(stop_words, data): \n",
        "  new_data = [] \n",
        "  for datapoint in data:  \n",
        "    temp = datapoint.split() \n",
        "    temp = [word for word in temp if not word in stop_words]\n",
        "    separator = ' '\n",
        "    temp = separator.join(temp)\n",
        "    new_data.append(temp) \n",
        "  return new_data\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRDsWfyu3bgh"
      },
      "source": [
        "#====================================================NAIVE BAYES CLASSIFIER============================================================\n",
        "import numpy as np\n",
        "def ClassifyNaiveBayes(Probability, testpoint):  \n",
        "  vocab = createVocabulary(train_real, train_fake)  \n",
        "  testpoint = testpoint.split() \n",
        "  training = [train_real, train_fake] \n",
        "  result = np.ones(2)\n",
        "  for i in range(0,2): \n",
        "    word_list = vocab\n",
        "    for word in testpoint: \n",
        "      if word in word_list:  \n",
        "        #print(Probability[i][idx])\n",
        "        result[i] += math.log(Probability[i][word_list.index(word)])\n",
        "      else: \n",
        "        result[i] += math.log(1) \n",
        "  prob_real, prob_fake = getClassProb(len(train_real), len(train_fake))\n",
        "  result[0]+= math.log(prob_real) \n",
        "  result[1]+= math.log(prob_fake)  \n",
        "  #print(result)\n",
        "  if result[0] > result[1]: \n",
        "    return 0 \n",
        "  return 1\n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPIi1Xxg8oIs"
      },
      "source": [
        "#====================================================EVALUATION MATRIC============================================================\n",
        "def EvaluationMetric(labels, predicted):\n",
        "  t_p = 1 \n",
        "  t_n = 1 \n",
        "  f_p = 1 \n",
        "  f_n = 1 \n",
        "  for i in range(0,len(labels)): \n",
        "    if labels[i] == 0 and predicted[i] == 0: \n",
        "      t_p +=1  \n",
        "    if labels[i] == 0 and predicted[i] == 1: \n",
        "      f_p +=1\n",
        "    if labels[i] == 1 and predicted[i] == 0: \n",
        "      f_n +=1\n",
        "    if labels[i] == 1 and predicted[i] == 1: \n",
        "      t_n +=1 \n",
        "  correct = 0 \n",
        "  for i in range(0, len(labels)): \n",
        "    if predicted[i]== labels[i]: \n",
        "      correct+=1 \n",
        "  \n",
        "  accuracy = correct/ len(labels) \n",
        "  precision = t_p / (t_p+f_p)\n",
        "  recall = t_p / (t_p+f_n) \n",
        "  f_1 = (2 * precision * recall)/ (precision + recall) \n",
        "  print(\"Accuracy: \", accuracy)\n",
        "  print(\"Precision: \", precision) \n",
        "  print(\"Recall: \", recall)\n",
        "  print(\"f1 score: \", f_1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8dXHce62b2B"
      },
      "source": [
        "def remove_duplicates(data): \n",
        "  new_data = [] \n",
        "  for datapoint in data:  \n",
        "    temp = datapoint.split() \n",
        "    temp = list(dict.fromkeys(temp))\n",
        "    separator = ' '\n",
        "    temp = separator.join(temp)\n",
        "    new_data.append(temp) \n",
        "  return new_data\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kecah9j7ufrf"
      },
      "source": [
        "**Predicting using Naive BayesClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6oPXyq0Q6YY"
      },
      "source": [
        "train_real_filename, train_fake_filename = getFilenames()\n",
        "train_real, train_fake = CreateDataset(train_real_filename, train_fake_filename) \n",
        "\n",
        "test_real_filename, test_fake_filename = getTestFilenames()\n",
        "test_real, test_fake = CreateTestDataset(test_real_filename, test_fake_filename)\n",
        "\n",
        "P = NaiveBayes(train_real, train_fake)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btr2W30ap6nB"
      },
      "source": [
        "copy_train_real = train_real\n",
        "copy_train_fake = train_fake \n",
        "copy_test_real = test_real\n",
        "copy_test_fake = test_fake "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHxvhDN_3dbU"
      },
      "source": [
        "predicted = []\n",
        "test = test_real + test_fake\n",
        "for t in test: \n",
        "  predicted.append(ClassifyNaiveBayes(P, t))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksGUmQs8vhxe"
      },
      "source": [
        "labels = []\n",
        "for i in range(len(test_real)): \n",
        "  labels.append(0)\n",
        "for i in range(len(test_fake)): \n",
        "  labels.append(1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJyxOQEPkVfd",
        "outputId": "d71c7450-5373-4001-856c-c6e5c99bb96d"
      },
      "source": [
        "print(\"===========================NAIVE BAYSE (without Stopwords)===============================================\")\n",
        "EvaluationMetric(labels, predicted)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6946564885496184\n",
            "Precision:  0.743421052631579\n",
            "Recall:  0.7243589743589743\n",
            "f1 score:  0.7337662337662338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8T2-DePk3AH"
      },
      "source": [
        "**Predict using Naive Bayes(StopWords remooved)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdiWrbAEqkMo"
      },
      "source": [
        "train_real = removeStopWords(stop_words, train_real)\n",
        "train_fake = removeStopWords(stop_words, train_fake)\n",
        "test_real = removeStopWords(stop_words, test_real)\n",
        "test_fake = removeStopWords(stop_words, test_fake)\n",
        "P = NaiveBayes(train_real, train_fake)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtlTHvz1rMPO"
      },
      "source": [
        "predicted = []\n",
        "test = test_real + test_fake\n",
        "for t in test: \n",
        "  predicted.append(ClassifyNaiveBayes(P, t))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJVCqWbBlEJx",
        "outputId": "418aa81a-f998-4ad1-f44c-c0135b99155b"
      },
      "source": [
        "print(\"===========================NAIVE BAYES (using Stopwords)===============================================\")\n",
        "EvaluationMetric(labels, predicted)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7022900763358778\n",
            "Precision:  0.7302631578947368\n",
            "Recall:  0.74\n",
            "f1 score:  0.7350993377483444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRcieS5l4iKT"
      },
      "source": [
        "**BOOLEAN NAIVE BAYES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU6h2xyyDT5T"
      },
      "source": [
        "train_real = copy_train_real  \n",
        "train_fake = copy_train_fake \n",
        "test_real = copy_test_real \n",
        "test_fake = copy_test_fake\n",
        "\n",
        "train_real = remove_duplicates(train_real) \n",
        "train_fake = remove_duplicates(train_fake)\n",
        "test_real = remove_duplicates(test_real) \n",
        "test_fake = remove_duplicates(test_fake)\n",
        "\n",
        "P = NaiveBayes(train_real, train_fake)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ldYu669ImQ"
      },
      "source": [
        "predicted = []\n",
        "test = test_real + test_fake\n",
        "for t in test: \n",
        "  predicted.append(ClassifyNaiveBayes(P, t))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGYTr2sZBlnL",
        "outputId": "41fe977e-7e0b-4558-fa9c-1d963fd8fe0e"
      },
      "source": [
        "print(\"===========================BOOLEAN NAIVE BAISE (without Stopwords)===============================================\")\n",
        "EvaluationMetric(labels, predicted)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7824427480916031\n",
            "Precision:  0.868421052631579\n",
            "Recall:  0.7719298245614035\n",
            "f1 score:  0.8173374613003096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkg3rx0WlaTJ"
      },
      "source": [
        "**Predicting Using Boolean Naive Bayes(Stop words removed)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YB6Ab6OlZR1"
      },
      "source": [
        "train_real = removeStopWords(stop_words, train_real)\n",
        "train_fake = removeStopWords(stop_words, train_fake)\n",
        "test_real = removeStopWords(stop_words, test_real)\n",
        "test_fake = removeStopWords(stop_words, test_fake)\n",
        "P = NaiveBayes(train_real, train_fake)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDoIQWOHBwvy"
      },
      "source": [
        "predicted = []\n",
        "test = test_real + test_fake\n",
        "for t in test: \n",
        "  predicted.append(ClassifyNaiveBayes(P, t))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqd_nA4xl0Db",
        "outputId": "7479fa7c-90c4-483f-84bf-2bda310874cb"
      },
      "source": [
        "print(\"===========================BOOLEAN NAIVE BAYES (with Stopwords)===============================================\")\n",
        "EvaluationMetric(labels, predicted)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7633587786259542\n",
            "Precision:  0.8552631578947368\n",
            "Recall:  0.7558139534883721\n",
            "f1 score:  0.8024691358024691\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}